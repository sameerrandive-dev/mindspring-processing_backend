# Notebook and Source Flow Documentation

## Overview

This document explains how **Notebooks** and **Sources** work together in the MindSpring platform, including their relationships, lifecycle, and data flow.

## Entity Relationships

```
User
  â””â”€â”€ Notebook (1:N)
       â”œâ”€â”€ Source (1:N)
       â”‚    â””â”€â”€ Chunk (1:N)
       â”œâ”€â”€ Conversation (1:N)
       â”œâ”€â”€ Quiz (1:N)
       â””â”€â”€ StudyGuide (1:N)
```

### Key Relationships

- **User â†’ Notebook**: One user can have many notebooks
- **Notebook â†’ Source**: One notebook can contain many sources (documents, URLs, text)
- **Source â†’ Chunk**: One source is split into many chunks for RAG
- **Notebook â†’ Conversation**: Conversations are scoped to a notebook
- **Source â†’ Conversation**: Conversations can reference a specific source (RAG mode)

---

## ğŸ““ Notebook Flow

### What is a Notebook?

A **Notebook** is a container for organizing learning materials and conversations. Think of it as a workspace for a specific topic or course.

**Properties**:
- `id`: Unique identifier (UUID)
- `owner_id`: User who owns the notebook
- `title`: Notebook name
- `description`: Optional description
- `language`: Language setting (default: "en")
- `tone`: Writing tone (default: "educational")
- `max_context_tokens`: Maximum tokens for context (default: 8000)
- `created_at`, `updated_at`, `deleted_at`: Timestamps

### Notebook Lifecycle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. CREATE NOTEBOOK                                      â”‚
â”‚    User creates a new notebook                          â”‚
â”‚    - Set title, description                             â”‚
â”‚    - Configure language, tone                           â”‚
â”‚    - Assign to user (owner_id)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. ADD SOURCES                                          â”‚
â”‚    User adds documents/URLs/text to notebook            â”‚
â”‚    - Upload PDFs                                        â”‚
â”‚    - Add URLs                                           â”‚
â”‚    - Paste text content                                 â”‚
â”‚    - Sources are processed and chunked                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. CREATE CONVERSATIONS                                 â”‚
â”‚    User starts conversations in notebook                â”‚
â”‚    - Normal chat: General conversation                 â”‚
â”‚    - RAG chat: Questions about sources                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. GENERATE NOTEBOOK-WIDE ARTIFACTS                     â”‚
â”‚    User creates artifacts from entire notebook          â”‚
â”‚    - Notebook Summary (detailed/bullets)                â”‚
â”‚    - Notebook Quiz (10-50 questions)                    â”‚
â”‚    - Notebook Study Guide (structured/outline)          â”‚
â”‚    - Notebook Mindmap (Mermaid/JSON)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. DELETE NOTEBOOK (Soft Delete)                        â”‚
â”‚    Notebook is marked as deleted                        â”‚
â”‚    - Can be restored                                    â”‚
â”‚    - Cascades to sources, chunks, conversations         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Notebook Operations

#### Create Notebook

```python
POST /api/v1/notebooks/
{
    "title": "Machine Learning Basics",
    "description": "Learning ML fundamentals",
    "language": "en",
    "tone": "educational"
}
```

**Flow**:
1. Validate input
2. Create notebook record
3. Set `owner_id` to current user
4. Return notebook with ID

#### List Notebooks

```python
GET /api/v1/notebooks/?skip=0&limit=20
```

**Returns**: List of user's notebooks with sources loaded

#### Get Notebook Details

```python
GET /api/v1/notebooks/{notebook_id}
```

**Returns**: Notebook with:
- All sources
- All conversations
- All chunks
- Metadata

#### Update Notebook

```python
PUT /api/v1/notebooks/{notebook_id}
{
    "title": "Updated Title",
    "description": "Updated description"
}
```

#### Notebook Generation (NotebookLM Features)

```python
# Generate notebook-wide summary
POST /api/v1/notebooks/{notebook_id}/generate/summary
{
    "max_length": 1000,
    "style": "detailed"
}

# Generate notebook-wide quiz
POST /api/v1/notebooks/{notebook_id}/generate/quiz
{
    "topic": "Python Fundamentals",
    "num_questions": 20,
    "difficulty": "intermediate"
}

# Generate notebook-wide study guide
POST /api/v1/notebooks/{notebook_id}/generate/guide
{
    "topic": "Exam 1 Prep",
    "format": "structured"
}

# Generate notebook-wide mindmap
POST /api/v1/notebooks/{notebook_id}/generate/mindmap
{
    "format": "mermaid"
}
```

**Flow**:
1. Aggregate all chunks from all sources in the notebook
2. Pass combined context to LLM with specific instructions
3. Save generated artifact in historical records/dedicated tables
4. Return the generated discovery/learning tool


#### Delete Notebook (Soft Delete)

```python
DELETE /api/v1/notebooks/{notebook_id}
```

**Cascade Behavior**:
- Sources are soft-deleted
- Chunks are soft-deleted
- Conversations are soft-deleted
- Can be restored later

---

## ğŸ“„ Source Flow

### What is a Source?

A **Source** is a document, URL, or text content added to a notebook. Sources are processed and split into chunks for RAG operations.

**Properties**:
- `id`: Unique identifier (UUID)
- `notebook_id`: Parent notebook
- `type`: Source type ("pdf", "url", "text", etc.)
- `title`: Source title
- `original_url`: URL if source is from web
- `file_path`: Path to file if uploaded
- `metadata_`: Additional metadata (JSONB)
- `status`: Processing status ("processing", "completed", "failed")
- `created_at`, `updated_at`, `deleted_at`: Timestamps

### Source Lifecycle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. UPLOAD/ADD SOURCE                                    â”‚
â”‚    User uploads document or adds URL                    â”‚
â”‚    - PDF upload                                         â”‚
â”‚    - URL submission                                     â”‚
â”‚    - Text paste                                         â”‚
â”‚    - Status: "processing"                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. PROCESS SOURCE (Background Job)                      â”‚
â”‚    Celery worker processes source                       â”‚
â”‚    - Extract text (PDF parsing, OCR)                    â”‚
â”‚    - Validate content                                   â”‚
â”‚    - Status: "processing"                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. CHUNK DOCUMENT                                       â”‚
â”‚    Text is split into chunks                            â”‚
â”‚    - Fixed-size chunks (512 chars)                      â”‚
â”‚    - Overlap (100 chars)                                â”‚
â”‚    - Create Chunk records                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. GENERATE EMBEDDINGS                                  â”‚
â”‚    Each chunk gets vector embedding                     â”‚
â”‚    - Call LLM embedding API                             â”‚
â”‚    - Store embeddings                                   â”‚
â”‚    - Status: "completed"                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. SOURCE READY FOR RAG                                â”‚
â”‚    Source can be used in RAG conversations              â”‚
â”‚    - Chunks searchable via vector similarity            â”‚
â”‚    - Can be referenced in conversations                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Source Processing Flow

#### Step 1: Upload Source

```python
POST /api/v1/documents/
Content-Type: multipart/form-data

file: <PDF file>
title: "Machine Learning Guide"
```

**What Happens**:
1. File is uploaded to storage (S3/CEPH)
2. Source record created with `status="processing"`
3. Background job created for processing
4. Return source ID immediately

#### Step 2: Background Processing

```python
# Celery worker picks up job
@celery_app.task
async def process_document(source_id: str):
    # 1. Download file from storage
    file_content = await storage.get(source.file_path)
    
    # 2. Extract text
    text = await pdf_service.extract_text(file_content)
    
    # 3. Chunk text
    chunks = rag_service.chunk_text(text)
    
    # 4. Generate embeddings
    embeddings = await llm_client.generate_embeddings(chunks)
    
    # 5. Store chunks with embeddings
    for chunk, embedding in zip(chunks, embeddings):
        await chunk_repo.create(
            source_id=source_id,
            notebook_id=source.notebook_id,
            plain_text=chunk,
            embedding=embedding
        )
    
    # 6. Update source status
    await source_repo.update(source_id, status="completed")
```

#### Step 3: Source Ready

Once processing completes:
- Source `status` changes to `"completed"`
- Chunks are available for RAG search
- Source can be used in RAG conversations

### Source Operations

#### Add Source to Notebook

```python
POST /api/v1/notebooks/{notebook_id}/sources
{
    "type": "pdf",
    "title": "ML Guide",
    "file_path": "documents/user-123/source-456/file.pdf"
}
```

**Flow**:
1. Verify user owns notebook
2. Create source record
3. Queue processing job
4. Return source with `status="processing"`

#### List Sources in Notebook

```python
GET /api/v1/notebooks/{notebook_id}/sources
```

**Returns**: All sources in notebook with:
- Processing status
- Chunk count
- Metadata

#### Get Source Details

```python
GET /api/v1/sources/{source_id}
```

**Returns**: Source with:
- All chunks
- Processing status
- Metadata

#### Delete Source

```python
DELETE /api/v1/sources/{source_id}
```

**Cascade Behavior**:
- Chunks are deleted (CASCADE)
- Conversations referencing source are updated
- File is deleted from storage

---

## ğŸ”„ Complete Flow: Document Upload to RAG Chat

### End-to-End Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: User Creates Notebook                         â”‚
â”‚                                                         â”‚
â”‚ POST /api/v1/notebooks/                                â”‚
â”‚ {                                                       â”‚
â”‚   "title": "ML Course",                                 â”‚
â”‚   "description": "Learning ML"                          â”‚
â”‚ }                                                       â”‚
â”‚                                                         â”‚
â”‚ â†’ Notebook created with ID: notebook-123               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: User Uploads Document                          â”‚
â”‚                                                         â”‚
â”‚ POST /api/v1/documents/                                 â”‚
â”‚ file: ml-guide.pdf                                      â”‚
â”‚                                                         â”‚
â”‚ â†’ Document uploaded                                     â”‚
â”‚ â†’ Source created: source-456                           â”‚
â”‚ â†’ Status: "processing"                                 â”‚
â”‚ â†’ Job queued: job-789                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: Background Worker Processes                    â”‚
â”‚                                                         â”‚
â”‚ Worker picks up job-789                                 â”‚
â”‚                                                         â”‚
â”‚ 1. Extract text from PDF                                â”‚
â”‚ 2. Chunk text (512 chars, 100 overlap)                  â”‚
â”‚ 3. Generate embeddings for chunks                       â”‚
â”‚ 4. Store chunks with embeddings                         â”‚
â”‚ 5. Update source status: "completed"                    â”‚
â”‚                                                         â”‚
â”‚ â†’ 50 chunks created                                     â”‚
â”‚ â†’ All chunks have embeddings                            â”‚
â”‚ â†’ Source ready for RAG                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: User Creates RAG Conversation                  â”‚
â”‚                                                         â”‚
â”‚ POST /api/v1/chat/conversations                         â”‚
â”‚ {                                                       â”‚
â”‚   "notebook_id": "notebook-123",                        â”‚
â”‚   "mode": "rag",                                        â”‚
â”‚   "source_id": "source-456"                             â”‚
â”‚ }                                                       â”‚
â”‚                                                         â”‚
â”‚ â†’ Conversation created: conv-999                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 5: User Asks Question                             â”‚
â”‚                                                         â”‚
â”‚ POST /api/v1/chat/conversations/conv-999/messages      â”‚
â”‚ {                                                       â”‚
â”‚   "content": "What is machine learning?"                â”‚
â”‚ }                                                       â”‚
â”‚                                                         â”‚
â”‚ Flow:                                                   â”‚
â”‚ 1. Generate query embedding                            â”‚
â”‚ 2. Search similar chunks (vector similarity)            â”‚
â”‚ 3. Filter by notebook_id and source_id                  â”‚
â”‚ 4. Get top 5 chunks                                     â”‚
â”‚ 5. Format chunks as context                            â”‚
â”‚ 6. Get conversation history                            â”‚
â”‚ 7. Generate LLM response with context                   â”‚
â”‚ 8. Save response with chunk_ids                         â”‚
â”‚                                                         â”‚
â”‚ â†’ Response includes relevant document chunks            â”‚
â”‚ â†’ Response cites sources                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Data Flow Diagram

```
User Action
    â”‚
    â”œâ”€â†’ Create Notebook
    â”‚       â”‚
    â”‚       â””â”€â†’ Notebook Record Created
    â”‚
    â”œâ”€â†’ Upload Document
    â”‚       â”‚
    â”‚       â”œâ”€â†’ Source Record Created (status: "processing")
    â”‚       â”œâ”€â†’ File Stored (S3/CEPH)
    â”‚       â””â”€â†’ Job Queued (Celery)
    â”‚               â”‚
    â”‚               â””â”€â†’ Worker Processes
    â”‚                       â”‚
    â”‚                       â”œâ”€â†’ Extract Text
    â”‚                       â”œâ”€â†’ Chunk Text
    â”‚                       â”œâ”€â†’ Generate Embeddings
    â”‚                       â””â”€â†’ Store Chunks
    â”‚                               â”‚
    â”‚                               â””â”€â†’ Source Status: "completed"
    â”‚
    â”œâ”€â†’ Create RAG Conversation
    â”‚       â”‚
    â”‚       â””â”€â†’ Conversation Record Created
    â”‚               â”‚
    â”‚               â””â”€â†’ Linked to Notebook & Source
    â”‚
    â””â”€â†’ Send Message
            â”‚
            â”œâ”€â†’ Retrieve Conversation History
            â”œâ”€â†’ Generate Query Embedding
            â”œâ”€â†’ Vector Search (find similar chunks)
            â”œâ”€â†’ Format Context (chunks + history)
            â”œâ”€â†’ Generate LLM Response
            â””â”€â†’ Save Response with chunk_ids
```

---

## ğŸ” Key Concepts

### Notebook Scope

- **All sources** in a notebook share the same context
- **All conversations** in a notebook can access all sources
- **Chunks** are scoped to both notebook and source
- **Quizzes and Study Guides** can be generated from the entire notebook context (all sources combined) or from a specific source.
- **Notebook Intelligence**: The system can synthesize a "big picture" view of the entire notebook contents.

### Source Types

1. **PDF Documents**
   - Uploaded files
   - Processed with OCR if needed
   - Extracted text is chunked

2. **URLs**
   - Web pages/articles
   - Content scraped and processed
   - Text is chunked

3. **Text**
   - Direct text input
   - Immediately chunked
   - No processing needed

### Chunk Organization

```
Notebook (notebook-123)
  â””â”€â”€ Source (source-456)
       â”œâ”€â”€ Chunk 1 (chunk-001) - embedding vector
       â”œâ”€â”€ Chunk 2 (chunk-002) - embedding vector
       â”œâ”€â”€ Chunk 3 (chunk-003) - embedding vector
       â””â”€â”€ ...
```

**Chunk Properties**:
- `source_id`: Parent source
- `notebook_id`: Parent notebook (for filtering)
- `plain_text`: Chunk text content
- `embedding`: Vector embedding (for similarity search)
- `chunk_index`: Order in source

### RAG Search Flow

When user asks a question in RAG conversation:

1. **Query Embedding**: Generate embedding for user question
2. **Vector Search**: Find similar chunks using cosine similarity
3. **Filtering**: Filter by `notebook_id` and optionally `source_id`
4. **Re-ranking**: Optional re-ranking by relevance
5. **Context Assembly**: Format top chunks as context
6. **LLM Generation**: Generate response using chunks + conversation history

---

## ğŸ¯ Use Cases

### Use Case 1: Course Material Organization

```
1. User creates notebook: "Python Programming Course"
2. User uploads multiple PDFs:
   - "Python Basics.pdf"
   - "Data Structures.pdf"
   - "Algorithms.pdf"
3. All sources are processed and chunked
4. User creates RAG conversation
5. User asks: "Explain lists in Python"
6. System finds relevant chunks from "Python Basics.pdf"
7. System generates response using chunks
```

### Use Case 2: Research Notebook

```
1. User creates notebook: "ML Research"
2. User adds multiple sources:
   - Research paper PDFs
   - Article URLs
   - Notes (text)
3. User creates multiple conversations:
   - One for each research question
4. Each conversation can access all sources
5. User asks questions across sources
```

### Use Case 3: Study Session

```
1. User creates notebook: "Exam Prep"
2. User uploads study materials
3. User creates normal chat conversation
4. User asks general questions (not source-specific)
5. System uses conversation history only
```

---

## ğŸ”§ Technical Implementation

### Database Schema

**Notebooks Table**:
```sql
CREATE TABLE notebooks (
    id UUID PRIMARY KEY,
    owner_id UUID REFERENCES users(id) ON DELETE CASCADE,
    title VARCHAR(500) NOT NULL,
    description TEXT,
    language VARCHAR(50) DEFAULT 'en',
    tone VARCHAR(50) DEFAULT 'educational',
    max_context_tokens INTEGER DEFAULT 8000,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    deleted_at TIMESTAMP WITH TIME ZONE
);
```

**Sources Table**:
```sql
CREATE TABLE sources (
    id UUID PRIMARY KEY,
    notebook_id UUID REFERENCES notebooks(id) ON DELETE CASCADE,
    type VARCHAR(50) NOT NULL,
    title VARCHAR(500) NOT NULL,
    original_url TEXT,
    file_path TEXT,
    metadata_ JSONB DEFAULT '{}',
    status VARCHAR(50) DEFAULT 'processing',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    deleted_at TIMESTAMP WITH TIME ZONE
);
```

**Chunks Table**:
```sql
CREATE TABLE chunks (
    id UUID PRIMARY KEY,
    source_id UUID REFERENCES sources(id) ON DELETE CASCADE,
    notebook_id UUID REFERENCES notebooks(id) ON DELETE CASCADE,
    plain_text TEXT NOT NULL,
    chunk_index INTEGER NOT NULL,
    embedding JSONB,  -- Will be replaced with vector column
    embedding_vector vector(1536),  -- pgvector column (to be added)
    metadata_ JSONB DEFAULT '{}',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);
```

### Indexes

```sql
-- Notebook queries
CREATE INDEX idx_notebooks_owner ON notebooks(owner_id);
CREATE INDEX idx_notebooks_active ON notebooks(owner_id) WHERE deleted_at IS NULL;

-- Source queries
CREATE INDEX idx_sources_notebook ON sources(notebook_id);
CREATE INDEX idx_sources_active ON sources(notebook_id) WHERE deleted_at IS NULL;

-- Chunk queries (RAG search)
CREATE INDEX idx_chunks_notebook ON chunks(notebook_id);
CREATE INDEX idx_chunks_source ON chunks(source_id);
CREATE INDEX idx_chunks_embedding_vector ON chunks USING hnsw (embedding_vector vector_cosine_ops);  -- To be added
```

---

## ğŸ“ Summary

### Notebook Flow
1. **Create** â†’ User creates notebook
2. **Add Sources** â†’ Documents/URLs added
3. **Process** â†’ Sources processed and chunked
4. **Use** â†’ Sources used in conversations/quizzes

### Source Flow
1. **Upload** â†’ File/URL added
2. **Process** â†’ Background job extracts text
3. **Chunk** â†’ Text split into chunks
4. **Embed** â†’ Chunks get vector embeddings
5. **Ready** â†’ Source available for RAG

### Key Relationships
- **Notebook** contains **Sources**
- **Sources** contain **Chunks**
- **Conversations** reference **Notebook** and optionally **Source**
- **Chunks** are searchable via vector similarity
- **RAG** uses chunks + conversation history

### Next Steps
- Implement pgvector for vector search
- Add semantic chunking
- Implement RAG retrieval service
- Add caching for frequently accessed chunks
